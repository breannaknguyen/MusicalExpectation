{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ccd444-aaaf-4063-b50f-8d1df8cd2f13",
   "metadata": {},
   "source": [
    "## **What comes next?: Using Bayesian Inference to Model Human Musical Expectation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198bfb9-cb69-458c-a733-48b33944a032",
   "metadata": {},
   "source": [
    "\"*We experience musical motions metaphorically in terms of our experience of physical motions.*\" - Steve Larson, 2004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbf097-69bd-4db1-9980-34efc7c64b45",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "When you listen to a song you have never heard before, does it feel like you can predict the notes before they occur? What if I played you five notes on the piano, could you predict the sixth? \n",
    "\n",
    "Melodic expectation is a fundamental concept of musical cognition, referring to the cognitive processes involved when one is tasked with predicting the next notes in a melody. An account of melodic expectation explores the idea of “musical forces'', which include gravity, magnetism, and inertia. These forces metaphorically reflect our “experience of physical motions''  (Larson, 2004, p. 458).\n",
    "\n",
    "**Gravity**: the tendency of an unstable note to descend\n",
    "\n",
    "**Magetism**: the tendency of an unstable note to move to the nearest stable pitch, a tendency that grows stronger the closer we get to a goal\n",
    "\n",
    "**Inertia**: the tendency of a pattern of musical motion to continue in the same fashion\n",
    "\n",
    "We propose a model of melodic expectation that combines both Temperly’s work on probabilistic inference of melodic structure and Larson’s work on musical forces using a Julia and Gen.jl, a probabilistic programming package. To solve this inference problem, we must create a generative model that solves a sequence of inference problems where the output of one is the input of another. The nature of this inference problem invites the utilization of a sequential Monte Carlo method called particle filtering. After a generative process is established, the model will be constrained on real-world data and the output will be compared to human performance in melodic expectation tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35592310-0d9c-4c77-89e5-9b851bbdbcc0",
   "metadata": {},
   "source": [
    "### **Background**\n",
    "\n",
    "#### **Calculating Musical Forces**\n",
    "Listeners (but not necessarily players) of music systematically expect completions of musical phrases where the aforementioned musical forces dictate the \"auralized traces\" (p. 459). In other words, we expect melodies to be completed *and* we expect gravity, magnetism, and intertia to be at play in these completions.\n",
    "\n",
    "However, the musical forces are not always interpreted in a consistent manner and are often context-dependent. Sometimes, the forces may agree on what the next note should be. Other times, each individual force may produce a different subsequent note. As such, Steve Larson, a melodic expectation researcher, created an algorithm to represent the interactions of these forces:\n",
    "\n",
    "$F = w_gG + w_mM + w_iI$\n",
    "\n",
    "where $G$, $M$, and $I$ are scores given to a certain pattern to denote whether it gives into the specific force and $w_g$, $w_m$, and $w_I$ the weights by which the three forces influence the cumulative effect, $F$ (pp. 462-465). \n",
    "\n",
    "$G$ is $1$ for patterns that give into gravity and $0$ otherwise.\n",
    "\n",
    "$M$ is represented by taking the inverse square of the distance in semitones to the a specific goal and subtracting the inverse square of the distance in semitones to the closest stable pitch in the other direction: $\\frac{1}{d_{\\text{to}}}^2 - \\frac{1}{d_{\\text{from}}}^2$\n",
    "\n",
    "$I$ is $1$ for patterns that give into intertia, $-1$ for ones that go against it, and $0$ otherwise.\n",
    "\n",
    "#### **Probabilistic Model**\n",
    "Taking a step back from the relationship between individual notes in a melody, David Temperley, a music theory professor, created a probabilistic model of melody perception using Bayesian inference. The objective of his model was to 1) identify keys of melodies, 2) judge the probability of different notes given the prior context, and 3) identify incorrect notes (Temperley, 2008).\n",
    "\n",
    "More generally, the model infers the most probable underlying structure (meter and key) of a melody given the perception  of the surface (pitches, error-detection, and expectation):\n",
    "\n",
    "$P(structure|surface) = \\frac{P(structure|surface)P(structure)}{P(surface)}$\n",
    "\n",
    "Since we are only interested in maximizing the right-hand side of the equation, we can rewrite it as this:\n",
    "\n",
    "$P(structure|surface) \\propto P(structure|surface)P(structure)$\n",
    "\n",
    "And simplify the right side further (p. 420):\n",
    "\n",
    "$P(structure|surface) \\propto P(structure, surface)$\n",
    "\n",
    "Researching musical cognition is strikingly similar to cognitive linguistics. As such, using a Bayesian approach to this aspect of musical cognition is appropriate because it is similar to other applications of statistical learning such as speech recognition and sentence processing (p. 421).\n",
    "\n",
    "The following model combines Larson's work on musical forces and Temperley's work on melody perception to reflect human performance in predictive musical tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31628dc7-c82e-49e0-9236-b2295df5ca09",
   "metadata": {},
   "source": [
    "### **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04e641-4fb2-4dd7-9f4e-48a23ff113e0",
   "metadata": {},
   "source": [
    "#### **Technical assumptions**\n",
    "- Pitches will be encoded using the MIDI note value system where C4 (middle C) = 60 and each semitone up or down from C4 is +1 or -1.\n",
    "- We will only be dealing with major scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebac1ba-b036-45d3-9eaa-64d5b4d6598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/music/Algorithms-of-the-Mind/finalproj/psyc261/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# Import dependecies\n",
    "import Pkg\n",
    "Pkg.activate(\"psyc261\")\n",
    "Pkg.add(\"Gen\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add([\"CSV\", \"DataFrames\"])\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"HypothesisTests\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"GLM\")\n",
    "using Gen\n",
    "using Plots\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Statistics\n",
    "using HypothesisTests\n",
    "using Random\n",
    "using GLM\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905318ce-ca28-479a-8d5d-808e674c2a42",
   "metadata": {},
   "source": [
    "First, we must define some structs and functions that will help with working with musical notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027de1d1-9263-455f-9bf9-1b1a3b882043",
   "metadata": {},
   "source": [
    "The struct represents a key and the notes in the scale of that key. \n",
    "\n",
    "The first helper function that creates a named scale from a root note (starting note) and specified intervals. I did this so I could create different types of scales with one function (major, minor, blues, etc.) Then, I create `notes()`, which returns the pitches of a scale as a vector from the name of the scale, and `create_major_scale()`, which creates a 2-octave scale from a root note and set intervals. I also create `findnearest()`, which finds the nearest stable note in a key to the inputted note. Lastly, I create some major scales to work with later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9037e727-b5d1-4b66-83bf-33b64191a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct MusicalScale\n",
    "    name::Symbol\n",
    "    notes::Vector{Int}\n",
    "end\n",
    "\n",
    "function create_scale(name::Symbol, root_note::Int, intervals::Vector{Int})\n",
    "    notes = Int[]\n",
    "    note = root_note\n",
    "\n",
    "    for interval in intervals\n",
    "        note = root_note + interval\n",
    "        push!(notes, note)\n",
    "    end\n",
    "\n",
    "    return MusicalScale(name, notes)\n",
    "end\n",
    "\n",
    "function notes(scale::MusicalScale)\n",
    "    return scale.notes\n",
    "end\n",
    "\n",
    "# This function creates a major scale using the specific intervals in all major scales\n",
    "function create_major_scale(root_note::Int)\n",
    "    return create_scale(Symbol(\"major\"), root_note, [0, 2, 4, 5, 7, 9, 11, 12, 14, 16, 17, 19, 21, 23, 24])\n",
    "end\n",
    "\n",
    "# This function finds the degree of a note in a scale if it exists, and the nearest stable note if not\n",
    "function findnearest(value, array, exclude=nothing)\n",
    "    filtered_array = isnothing(exclude) ? array : filter(x -> x != exclude, array)\n",
    "    idx = argmin(abs.(value .- filtered_array))\n",
    "    return filtered_array[idx]\n",
    "end\n",
    "\n",
    "# I create some major scales for the model to draw from later on\n",
    "C = create_major_scale(60)\n",
    "G = create_major_scale(55)  \n",
    "D = create_major_scale(62)  \n",
    "A = create_major_scale(57)  \n",
    "E = create_major_scale(64)  \n",
    "B = create_major_scale(59)  \n",
    "F♯ = create_major_scale(66)\n",
    "G♭ = create_major_scale(66)\n",
    "D♭ = create_major_scale(61)\n",
    "A♭ = create_major_scale(56)\n",
    "E♭ = create_major_scale(63)\n",
    "B♭ = create_major_scale(58)\n",
    "F = create_major_scale(65)\n",
    "\n",
    "major_scales = [C, G, D, A, E, B, F♯, G♭, D♭, A♭, E♭, B♭, F]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fa73c-e378-4a43-95f8-88a0033bed0f",
   "metadata": {},
   "source": [
    "#### **Calculating musical forces**\n",
    "I also need to create some functions to calculate the musical forces. All of these functions will take the key and current pitch (as an integer) as inputs and output to what extent each force should be applied given the position of the note in the scale (the degree) and the scale iteself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3b8d1-78c4-4857-8bee-2b6aeba833e3",
   "metadata": {},
   "source": [
    "Here is a function that calculates to what extent gravity should influence the following note. First, it initializes `gravity_force` at 0.0. Then, it searches within the notes of the key to determine the position of the note. \n",
    "\n",
    "If the note exists in the key, then the gravity force is -0.05 times the degree. If the note does not exist in the key, then the gravity force is -0.05 times the distance to the nearest stable pitch in the key. This implementation allows the gravity force to be proportional to the degree if the note exists in the scale and proportional to the distance to the nearest stable pitch otherwise. In practice, this means that notes that are of a higher degree are more heavily influenced by gravity and notes that are not part of the scale to be less influenced by gravity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6fb751-6ccd-4eac-b724-fc921584ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_gravity(note::Float64, key::MusicalScale)\n",
    "    gravity_force = 0.0\n",
    "    degree = findfirst(x -> x == note, values(notes(key)))\n",
    "    if degree !== nothing\n",
    "        gravity_force = -0.05 * degree\n",
    "    else\n",
    "        nearest_stable_pitch = findnearest(note, values(key.notes))\n",
    "        gravity_force = -0.05 * abs(note - nearest_stable_pitch)\n",
    "    end\n",
    "\n",
    "    return gravity_force\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695de634-8c11-4fa8-87a9-05d50a514504",
   "metadata": {},
   "source": [
    "Here is a function that calculates to what extent magnetism should influence the following note. First, it initializes `magnetism_force` at 0.0. Then, it searches for the nearest stable pitch. `dto` is the distance to the nearest stable pitch. `dfrom` is the distance to the next nearest stable pitch. This function employs the magnetism formula from the background to yield a final value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5071a1-dcf2-4fd9-8fee-265b3fc38450",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_magnetism(note::Float64, key::MusicalScale)\n",
    "    magnetism_force = 0.0\n",
    "    nearest_stable_pitch = findnearest(note, values(notes(key)))\n",
    "\n",
    "    dto = abs(note - nearest_stable_pitch)\n",
    "    dfrom = abs(note - findnearest(note, values(notes(key)), nearest_stable_pitch))\n",
    "\n",
    "    # This is so we don't get -Inf from dividng by 0\n",
    "    if dto != 0.0 && dfrom != 0.0\n",
    "        magnetism_force = (1/dto)^2 - (1/dfrom)^2\n",
    "    end\n",
    "\n",
    "    return magnetism_force\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4c53e-e4eb-4e0c-9ad4-90a3aab4cab6",
   "metadata": {},
   "source": [
    "Here is a function that calculates to what extent inertia should influence the following note. Notice that this function is a bit different from the previous two as it also takes the previous note in the sequence as the third argument. If there is no previous note, then the function will output 0 since there is no set direction yet.\n",
    "\n",
    "First, the function initializes `inertia_force` at 0.0. Then, it searches within the notes of the key to determine the position of the note. It also determines if the current note is above or below `previous_note`. Lastly, `inertia_force` is proportional to the degree of the note and is positive or negative depending on the current direction of notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a56addf-f17e-4877-8cf4-719e4e9c3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_inertia(note::Float64, key::MusicalScale, tmp_sequence::Vector{Any})\n",
    "    inertia_force = 0.0\n",
    "    degree = findfirst(x -> x == note, values(notes(key)))\n",
    "\n",
    "    #Retrieve last note from sequence\n",
    "    prev_note = tmp_sequence[end]\n",
    "    \n",
    "    if note > prev_note\n",
    "        if degree !== nothing\n",
    "            inertia_force = 0.5 * degree\n",
    "        else\n",
    "            inertia_force = 0.5\n",
    "        end\n",
    "    elseif note < prev_note\n",
    "        if degree !== nothing\n",
    "            inertia_force = -0.5 * degree\n",
    "        else\n",
    "            inertia_force = -0.5\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return inertia_force\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f2169-3d2d-44da-b2a1-926feb92e08b",
   "metadata": {},
   "source": [
    "Next, I need to create a kernel function which will be called in a different function later on. This function takes in the current note and key, and applies the musical force algorithm to determine the next note. I also create `chain()` using Gen's unfold combinator. This function passes the return value of one application of the kernel function to the next application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08822d4c-e7c5-4b2a-8ae6-dca2234f7eb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@gen` not defined\nin expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@gen` not defined\n",
      "in expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@gen function melody_kernel(k::Int, curr_note::Float64, key::MusicalScale, tmp_sequence::Vector{Any})\n",
    "    σ = 0.5\n",
    "    w_g = 1\n",
    "    w_m = 9\n",
    "    w_i = 2\n",
    "    push!(tmp_sequence, curr_note)\n",
    "    \n",
    "    #First, calculate each force\n",
    "    gravity = @trace(normal(calculate_gravity(curr_note, key), σ), :gravity)\n",
    "    magnetism = @trace(normal(calculate_magnetism(curr_note, key), σ), :magnetism)\n",
    "    inertia = @trace(normal(calculate_inertia(curr_note, key, tmp_sequence), σ), :inertia)\n",
    "\n",
    "    #Add all forces together to get cumulative `F`\n",
    "    force = w_g*gravity + w_m*magnetism + w_i*inertia\n",
    "\n",
    "    #Apply force to find next note\n",
    "    next_note = round(curr_note + force)\n",
    "\n",
    "    return next_note\n",
    "end \n",
    "\n",
    "chain = Gen.Unfold(melody_kernel)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa463702-6651-4de7-b974-f2dd6ecaa1b0",
   "metadata": {},
   "source": [
    "Here is the main generative function. It randomly draws on the major keys I created earlier and draws a start note from a normal distribution with µ being the middle note of scale and σ being 0.05. It then calls the chain function from before to return a sequence of notes using the kernel function.\n",
    "\n",
    "Let's ask it to make a melody with 10 notes as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888dd8ed-c72c-46b8-a5f9-aabf95e45e1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@gen` not defined\nin expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@gen` not defined\n",
      "in expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@gen function melody(K::Int, init_note=nothing, key=nothing)\n",
    "    σ = 0.05\n",
    "    \n",
    "    #This is so I can keep track of note directions for inertia\n",
    "    tmp_sequence = []\n",
    "\n",
    "    #Choose some things to start the melody\n",
    "    key = @trace(draw(major_scales, (ones(length(major_scales)) / length(major_scales))), :key)\n",
    "    start = @trace(normal((notes(key)[8]), σ), :start)\n",
    "    init_note = round(start)\n",
    "\n",
    "    sequence ~ chain(K, init_note, key, tmp_sequence)\n",
    "\n",
    "    return sequence\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d5f58d-f5fa-4d95-8f15-a16af61b0ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Gen` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Gen` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "trace = Gen.simulate(melody, (10,)) \n",
    "get_retval(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61ff124-613c-4af8-9cd1-a7f0f990fac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `get_choices` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `get_choices` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "get_choices(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af947d-8aa0-4077-ae0b-38c84313a876",
   "metadata": {},
   "source": [
    "#### **Particle Filtering**\n",
    "Next, I will implement a basic particle filter to better solve this inference problem. The structures of the following functions is intentionally tailored to the existing dataset that I have. A study by Morgan et al. (2019) asked participants to listen to a \"melodic stem\", a set of 6-9 notes that make the beginning of a melody, and sing what they think the last note should be. The purpose of my model is to output a similar end note to the human participants. First, I will create `make_observations` which creates a data frame from a vector of notes and the key with gravity, magnetism, and inertia values at each time step. This data frame will be used to load observations into the particle filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3c71d4-3134-4d38-a5bc-03a4ad63aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_observations(notes::Vector{Float64}, key::MusicalScale)\n",
    "    tmp_sequence = []\n",
    "    observed_notes = notes\n",
    "    scale_vec = repeat([key], length(notes))\n",
    "    gravity = calculate_gravity.(observed_notes, scale_vec)\n",
    "    magnetism = calculate_magnetism.(observed_notes, scale_vec)\n",
    "    inertia = []\n",
    "    for i in 1:length(observed_notes)\n",
    "        push!(tmp_sequence, init_note)\n",
    "        tmp_inertia = calculate_inertia(observed_notes[i], key, tmp_sequence)\n",
    "        push!(tmp_sequence, observed_notes[i])\n",
    "        push!(inertia, tmp_inertia)\n",
    "    end\n",
    "    \n",
    "    obs_notes = DataFrame(obs_notes = observed_notes, gravity = gravity, magnetism = magnetism, inertia = inertia)\n",
    "\n",
    "    return obs_notes\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fafbd0-5d23-4911-9d42-52d0740fd121",
   "metadata": {},
   "source": [
    "I am using one example melody (for now) from the behavioral data to update the beliefs of the this particle filter at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9345428f-7f9f-4069-883b-a5b8c85464f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `DataFrame` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `DataFrame` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] make_observations(notes::Vector{Float64}, key::MusicalScale)\n",
      "   @ Main ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:15\n",
      " [2] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:4"
     ]
    }
   ],
   "source": [
    "key = G\n",
    "init_note = 62.0\n",
    "observed_notes = [62.0, 59.0, 55.0, 62.0, 64.0, 60.0, 66.0, 62.0]\n",
    "obs_notes = make_observations(observed_notes, key)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13db2e4-40a8-4cab-923e-fe5cd9249349",
   "metadata": {},
   "outputs": [],
   "source": [
    "function particle_filter(num_particles::Int, num_samples::Int, key::MusicalScale, obs_notes, init_note)\n",
    "    \n",
    "    # Initial observations\n",
    "    init_obs = Gen.choicemap(\n",
    "        (:key, key),\n",
    "        (:start, init_note)\n",
    "    )\n",
    "\n",
    "    # Initialize the particle filter\n",
    "    state = Gen.initialize_particle_filter(melody, (0,), init_obs, num_particles)\n",
    "\n",
    "    last_notes = Float64[]\n",
    "\n",
    "    for (idx, obs_note) in enumerate(eachrow(obs_notes))\n",
    "        # Evolve and resample\n",
    "        Gen.maybe_resample!(state, ess_threshold=num_particles / 2)\n",
    "\n",
    "        # Load observations of this time step\n",
    "        obs = Gen.choicemap(\n",
    "            (:sequence => idx => :obs_gravity, obs_notes[idx, :gravity]),\n",
    "            (:sequence => idx => :obs_magnetism, obs_notes[idx, :magnetism]),\n",
    "            (:sequence => idx => :inertia, obs_notes[idx, :inertia]),\n",
    "        )\n",
    "\n",
    "        # Re-weight by the likelihood\n",
    "        Gen.particle_filter_step!(state, (idx,), (UnknownChange(),), obs)\n",
    "    end\n",
    "    \n",
    "    # Return a sample of unweighted traces from the weighted collection\n",
    "    return Gen.sample_unweighted_traces(state, num_samples)\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce83933-7f42-4836-9df7-40d36b85d159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Random` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Random` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "Random.seed!(704)\n",
    "pf_traces = particle_filter(2000, 200, key, obs_notes, init_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21063d91-2a86-43fa-8074-5059a5d8073a",
   "metadata": {},
   "source": [
    "I've created a function to easily visualize the samples from the particle filter. Let's visualize the samples and calculate the mean of the last note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e83dbb-fa18-4037-8c4d-e14330c1c551",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Gen` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Gen` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "function visualize_samples(samples::Vector{Gen.DynamicDSLTrace}, obs_notes::Vector{Float64})\n",
    "    plot()\n",
    "    for trace in samples\n",
    "        sequence = Vector(trace[:sequence])\n",
    "        # Because of the way that melody works, it only logs the following notes after the first one, so I\n",
    "        # added it back here\n",
    "        pushfirst!(sequence, init_note)\n",
    "        plot!(sequence, linewidth=2, alpha=0.5, legend=false)\n",
    "    end\n",
    "    plot!(obs_notes, linewidth=4, linecolor=:red, linestyle=:solid, label=\"Observed Sequence\")\n",
    "    xlabel!(\"Time Step\")\n",
    "    ylabel!(\"Note\")\n",
    "    title!(\"Particle Filter Samples\")\n",
    "    display(Plots.plot!())\n",
    "end\n",
    "\n",
    "init_note = 62.0\n",
    "observed_notes = [62.0, 59.0, 55.0, 62.0, 64.0, 60.0, 66.0, 62.0, 67.0]\n",
    "visualize_samples(pf_traces, observed_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e26d5e-3b1a-45a6-94eb-226404e1adb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `pf_traces` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `pf_traces` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:2"
     ]
    }
   ],
   "source": [
    "last_notes = Float64[]\n",
    "for trace in pf_traces\n",
    "    last_note = trace[:sequence][end]\n",
    "    push!(last_notes, last_note)\n",
    "end\n",
    "\n",
    "mu = mean(last_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a502b01-903d-4ca6-af82-bcc2c6a02f2b",
   "metadata": {},
   "source": [
    "Seems pretty close to the actual last note! (67.0) Let's do this on all of the melodic stems to get a better picture of how the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082764be-533d-490b-9c7a-b1c1d22c16db",
   "metadata": {},
   "source": [
    "### **Experiment: Model vs Human Performance in Melodic Expectation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2416e6-59ea-434b-b5bb-3e69fd305160",
   "metadata": {},
   "source": [
    "First, I'll need to read the data into a workable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d39dcf-07f1-4f50-9ebd-a1d7e2d8e1b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `CSV` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `CSV` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:2"
     ]
    }
   ],
   "source": [
    "# I had to make separate df's for different melody lengths, the code breaks otherwise\n",
    "df6 = DataFrame(CSV.File(\"./data/stems6.csv\"))\n",
    "melodies6 = []\n",
    "for col in names(df6)\n",
    "    push!(melodies6, df6[!, col][1:7])\n",
    "end\n",
    "df6_keys = [D,C]\n",
    "actual_means6 = Array(df6[7, :])\n",
    "\n",
    "df7 = DataFrame(CSV.File(\"./data/stems7.csv\"))\n",
    "melodies7 = []\n",
    "for col in names(df7)\n",
    "    push!(melodies7, df7[!, col][1:8])\n",
    "end\n",
    "df7_keys = [E,E♭,D♭,B♭]\n",
    "actual_means7 = Array(df7[8, :])\n",
    "\n",
    "df8 = DataFrame(CSV.File(\"./data/stems8.csv\"))\n",
    "melodies8 = []\n",
    "for col in names(df8)\n",
    "    push!(melodies8, df8[!, col][1:9])\n",
    "end\n",
    "df8_keys = [G,B,E♭,E,B,F♯,E♭,E,D♭,A♭,C,G,F,E♭]\n",
    "actual_means8 = Array(df8[9, :])\n",
    "\n",
    "df9 = DataFrame(CSV.File(\"./data/stems9.csv\"))\n",
    "melodies9 = []\n",
    "for col in names(df9)\n",
    "    push!(melodies9, df9[!, col][1:9])\n",
    "end\n",
    "df9_keys = [F♯,A♭,B♭,F,C,G,D,A,A♭,B♭,F,D,A,B,F♯,E♭,F,D,E,B,F♯,D♭,A♭,B♭,F]\n",
    "actual_means9 = Array(df9[9, :])\n",
    "\n",
    "actual_means = vcat(actual_means6, actual_means7, actual_means8, actual_means9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e1370-3a1c-4188-9dc7-18a6ab7dde62",
   "metadata": {},
   "source": [
    "Here is where I run the particle filter on all of the melodies. In the end, I'll make a scatterplot and do a correlation test to see how well my model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11d6e0bb-1bd2-4135-b0e1-ad8ceeef3151",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Random` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Random` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "Random.seed!(704)\n",
    "\n",
    "num_melodies = size(df6, 2)\n",
    "model_means = []\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df6[!, col_idx][1:7]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:6], df6_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df6_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "    \n",
    "    push!(model_means, mean(last_notes))\n",
    "    \n",
    "end\n",
    "\n",
    "num_melodies = size(df7, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df7[!, col_idx][1:8]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:7], df7_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df7_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df8, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df8[!, col_idx][1:9]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:8], df8_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df8_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df9, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df9[!, col_idx][1:10]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:9], df9_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df9_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93181904-89d8-452a-8e24-0ba5867836ce",
   "metadata": {},
   "source": [
    "### **Final results!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bad7044-e3f7-4f4f-8c4d-977068f32fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `cor` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `cor` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "r_value = cor(actual_means, model_means)\n",
    "ctest = CorrelationTest(actual_means, model_means)\n",
    "p_value = pvalue(ctest)\n",
    "\n",
    "viz = scatter(model_means, actual_means, xlabel=\"Model Performance\", ylabel=\"Human Performance\", legend=false)\n",
    "df = DataFrame(Y = convert(Array{Float64, 1}, model_means), x = convert(Array{Float64, 1}, actual_means))\n",
    "line = lm(@formula(Y~x), df)\n",
    "rsq = r2(line)\n",
    "x_vals = range(minimum(df.x), maximum(df.x), length=100)\n",
    "y_vals = predict(line, DataFrame(x=x_vals))\n",
    "\n",
    "display(plot!(viz, y_vals, x_vals, linewidth=2))\n",
    "println(\"R value = $r_value, R-squared value = $rsq, p = $p_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2824ff4-7163-405b-afeb-4608bc82d7ec",
   "metadata": {},
   "source": [
    "### **Ablation**\n",
    "How does the performance of the model change when I subset the physical forces?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386d1bb-48a7-4299-804d-545bcee152e5",
   "metadata": {},
   "source": [
    "#### **Subset with just magnetism and inertia, no gravity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12376ed9-e264-49f4-9e74-4da9c6752b4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@gen` not defined\nin expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@gen` not defined\n",
      "in expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@gen function melody_kernel_no_grav(k::Int, curr_note::Float64, key::MusicalScale, tmp_sequence::Vector{Any})\n",
    "    σ = 0.5\n",
    "    w_g = 1\n",
    "    w_m = 9\n",
    "    w_i = 2\n",
    "    push!(tmp_sequence, curr_note)\n",
    "    \n",
    "    #First, calculate each force\n",
    "    magnetism = @trace(normal(calculate_magnetism(curr_note, key), σ), :magnetism)\n",
    "    inertia = @trace(normal(calculate_inertia(curr_note, key, tmp_sequence), σ), :inertia)\n",
    "\n",
    "    #Add all forces together to get cumulative `F`\n",
    "    force = w_m*magnetism + w_i*inertia\n",
    "\n",
    "    #Apply force to find next note\n",
    "    next_note = round(curr_note + force)\n",
    "\n",
    "    return next_note\n",
    "end \n",
    "\n",
    "chain = Gen.Unfold(melody_kernel_no_grav)\n",
    ";\n",
    "\n",
    "function particle_filter(num_particles::Int, num_samples::Int, key::MusicalScale, obs_notes, init_note)\n",
    "    \n",
    "    # Initial observations\n",
    "    init_obs = Gen.choicemap(\n",
    "        (:key, key),\n",
    "        (:start, init_note)\n",
    "    )\n",
    "\n",
    "    # Initialize the particle filter\n",
    "    state = Gen.initialize_particle_filter(melody, (0,), init_obs, num_particles)\n",
    "\n",
    "    last_notes = Float64[]\n",
    "\n",
    "    for (idx, obs_note) in enumerate(eachrow(obs_notes))\n",
    "        # Evolve and resample\n",
    "        Gen.maybe_resample!(state, ess_threshold=num_particles / 2)\n",
    "\n",
    "        # Load observations of this time step\n",
    "        obs = Gen.choicemap(\n",
    "            (:sequence => idx => :obs_magnetism, obs_notes[idx, :magnetism]),\n",
    "            (:sequence => idx => :inertia, obs_notes[idx, :inertia]),\n",
    "        )\n",
    "\n",
    "        # Re-weight by the likelihood\n",
    "        Gen.particle_filter_step!(state, (idx,), (UnknownChange(),), obs)\n",
    "    end\n",
    "    \n",
    "    # Return a sample of unweighted traces from the weighted collection\n",
    "    return Gen.sample_unweighted_traces(state, num_samples)\n",
    "end\n",
    ";\n",
    "\n",
    "Random.seed!(704)\n",
    "\n",
    "num_melodies = size(df6, 2)\n",
    "model_means = []\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df6[!, col_idx][1:7]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:6], df6_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df6_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "    \n",
    "    push!(model_means, mean(last_notes))\n",
    "    \n",
    "end\n",
    "\n",
    "num_melodies = size(df7, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df7[!, col_idx][1:8]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:7], df7_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df7_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df8, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df8[!, col_idx][1:9]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:8], df8_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df8_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df9, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df9[!, col_idx][1:10]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:9], df9_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df9_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "r_value = cor(actual_means, model_means)\n",
    "ctest = CorrelationTest(actual_means, model_means)\n",
    "p_value = pvalue(ctest)\n",
    "\n",
    "viz = scatter(model_means, actual_means, xlabel=\"Model Performance\", ylabel=\"Human Performance\", legend=false)\n",
    "df = DataFrame(Y = convert(Array{Float64, 1}, model_means), x = convert(Array{Float64, 1}, actual_means))\n",
    "line = lm(@formula(Y~x), df)\n",
    "rsq = r2(line)\n",
    "x_vals = range(minimum(df.x), maximum(df.x), length=100)\n",
    "y_vals = predict(line, DataFrame(x=x_vals))\n",
    "\n",
    "display(plot!(viz, y_vals, x_vals, linewidth=2))\n",
    "println(\"R value = $r_value, R-squared value = $rsq, p = $p_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65d898-fe51-4324-b87c-e25e0607847c",
   "metadata": {},
   "source": [
    "#### **Subset with just gravity and inertia, no magnetism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de172e19-4c2a-40e1-bf4d-d5ab76ed3c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@gen` not defined\nin expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@gen` not defined\n",
      "in expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@gen function melody_kernel_no_mag(k::Int, curr_note::Float64, key::MusicalScale, tmp_sequence::Vector{Any})\n",
    "    σ = 0.5\n",
    "    w_g = 1\n",
    "    w_m = 9\n",
    "    w_i = 2\n",
    "    push!(tmp_sequence, curr_note)\n",
    "    \n",
    "    #First, calculate each force\n",
    "    gravity = @trace(normal(calculate_gravity(curr_note, key), σ), :gravity)\n",
    "    inertia = @trace(normal(calculate_inertia(curr_note, key, tmp_sequence), σ), :inertia)\n",
    "\n",
    "    #Add all forces together to get cumulative `F`\n",
    "    force = w_g*gravity + w_i*inertia\n",
    "\n",
    "    #Apply force to find next note\n",
    "    next_note = round(curr_note + force)\n",
    "\n",
    "    return next_note\n",
    "end \n",
    "\n",
    "chain = Gen.Unfold(melody_kernel_no_mag)\n",
    ";\n",
    "\n",
    "function particle_filter(num_particles::Int, num_samples::Int, key::MusicalScale, obs_notes, init_note)\n",
    "    \n",
    "    # Initial observations\n",
    "    init_obs = Gen.choicemap(\n",
    "        (:key, key),\n",
    "        (:start, init_note)\n",
    "    )\n",
    "\n",
    "    # Initialize the particle filter\n",
    "    state = Gen.initialize_particle_filter(melody, (0,), init_obs, num_particles)\n",
    "\n",
    "    last_notes = Float64[]\n",
    "\n",
    "    for (idx, obs_note) in enumerate(eachrow(obs_notes))\n",
    "        # Evolve and resample\n",
    "        Gen.maybe_resample!(state, ess_threshold=num_particles / 2)\n",
    "\n",
    "        # Load observations of this time step\n",
    "        obs = Gen.choicemap(\n",
    "            (:sequence => idx => :obs_gravity, obs_notes[idx, :gravity]),\n",
    "            (:sequence => idx => :inertia, obs_notes[idx, :inertia]),\n",
    "        )\n",
    "\n",
    "        # Re-weight by the likelihood\n",
    "        Gen.particle_filter_step!(state, (idx,), (UnknownChange(),), obs)\n",
    "    end\n",
    "    \n",
    "    # Return a sample of unweighted traces from the weighted collection\n",
    "    return Gen.sample_unweighted_traces(state, num_samples)\n",
    "end\n",
    ";\n",
    "\n",
    "Random.seed!(704)\n",
    "\n",
    "num_melodies = size(df6, 2)\n",
    "model_means = []\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df6[!, col_idx][1:7]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:6], df6_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df6_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "    \n",
    "    push!(model_means, mean(last_notes))\n",
    "    \n",
    "end\n",
    "\n",
    "num_melodies = size(df7, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df7[!, col_idx][1:8]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:7], df7_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df7_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df8, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df8[!, col_idx][1:9]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:8], df8_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df8_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df9, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df9[!, col_idx][1:10]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:9], df9_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df9_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "r_value = cor(actual_means, model_means)\n",
    "ctest = CorrelationTest(actual_means, model_means)\n",
    "p_value = pvalue(ctest)\n",
    "\n",
    "viz = scatter(model_means, actual_means, xlabel=\"Model Performance\", ylabel=\"Human Performance\", legend=false)\n",
    "df = DataFrame(Y = convert(Array{Float64, 1}, model_means), x = convert(Array{Float64, 1}, actual_means))\n",
    "line = lm(@formula(Y~x), df)\n",
    "rsq = r2(line)\n",
    "x_vals = range(minimum(df.x), maximum(df.x), length=100)\n",
    "y_vals = predict(line, DataFrame(x=x_vals))\n",
    "\n",
    "display(plot!(viz, y_vals, x_vals, linewidth=2))\n",
    "println(\"R value = $r_value, R-squared value = $rsq, p = $p_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3251c-3b28-477b-8ec4-779bba4c00d5",
   "metadata": {},
   "source": [
    "#### **Subset with just gravity and magnetism, no inertia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45a70ed-a631-4f4c-b419-5864fe330be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@gen` not defined\nin expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@gen` not defined\n",
      "in expression starting at /Users/breannanguyen/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@gen function melody_kernel_no_in(k::Int, curr_note::Float64, key::MusicalScale, tmp_sequence::Vector{Any})\n",
    "    σ = 0.5\n",
    "    w_g = 1\n",
    "    w_m = 9\n",
    "    w_i = 2\n",
    "    push!(tmp_sequence, curr_note)\n",
    "    \n",
    "    #First, calculate each force\n",
    "    gravity = @trace(normal(calculate_gravity(curr_note, key), σ), :gravity)\n",
    "    magnetism = @trace(normal(calculate_magnetism(curr_note, key), σ), :magnetism)\n",
    "    \n",
    "    #Add all forces together to get cumulative `F`\n",
    "    force = w_g*gravity + w_m*magnetism\n",
    "\n",
    "    #Apply force to find next note\n",
    "    next_note = round(curr_note + force)\n",
    "\n",
    "    return next_note\n",
    "end \n",
    "\n",
    "chain = Gen.Unfold(melody_kernel_no_in)\n",
    ";\n",
    "\n",
    "function particle_filter(num_particles::Int, num_samples::Int, key::MusicalScale, obs_notes, init_note)\n",
    "    \n",
    "    # Initial observations\n",
    "    init_obs = Gen.choicemap(\n",
    "        (:key, key),\n",
    "        (:start, init_note)\n",
    "    )\n",
    "\n",
    "    # Initialize the particle filter\n",
    "    state = Gen.initialize_particle_filter(melody, (0,), init_obs, num_particles)\n",
    "\n",
    "    last_notes = Float64[]\n",
    "\n",
    "    for (idx, obs_note) in enumerate(eachrow(obs_notes))\n",
    "        # Evolve and resample\n",
    "        Gen.maybe_resample!(state, ess_threshold=num_particles / 2)\n",
    "\n",
    "        # Load observations of this time step\n",
    "        obs = Gen.choicemap(\n",
    "            (:sequence => idx => :obs_gravity, obs_notes[idx, :gravity]),\n",
    "            (:sequence => idx => :inertia, obs_notes[idx, :inertia]),\n",
    "        )\n",
    "\n",
    "        # Re-weight by the likelihood\n",
    "        Gen.particle_filter_step!(state, (idx,), (UnknownChange(),), obs)\n",
    "    end\n",
    "    \n",
    "    # Return a sample of unweighted traces from the weighted collection\n",
    "    return Gen.sample_unweighted_traces(state, num_samples)\n",
    "end\n",
    ";\n",
    "\n",
    "Random.seed!(704)\n",
    "\n",
    "num_melodies = size(df6, 2)\n",
    "model_means = []\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df6[!, col_idx][1:7]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:6], df6_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df6_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "    \n",
    "    push!(model_means, mean(last_notes))\n",
    "    \n",
    "end\n",
    "\n",
    "num_melodies = size(df7, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df7[!, col_idx][1:8]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:7], df7_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df7_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df8, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df8[!, col_idx][1:9]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:8], df8_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df8_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df9, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df9[!, col_idx][1:10]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:9], df9_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df9_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    push!(model_means, mean(last_notes))\n",
    "end\n",
    "\n",
    "r_value = cor(actual_means, model_means)\n",
    "ctest = CorrelationTest(actual_means, model_means)\n",
    "p_value = pvalue(ctest)\n",
    "\n",
    "viz = scatter(model_means, actual_means, xlabel=\"Model Performance\", ylabel=\"Human Performance\", legend=false)\n",
    "df = DataFrame(Y = convert(Array{Float64, 1}, model_means), x = convert(Array{Float64, 1}, actual_means))\n",
    "line = lm(@formula(Y~x), df)\n",
    "rsq = r2(line)\n",
    "x_vals = range(minimum(df.x), maximum(df.x), length=100)\n",
    "y_vals = predict(line, DataFrame(x=x_vals))\n",
    "\n",
    "display(plot!(viz, y_vals, x_vals, linewidth=2))\n",
    "println(\"R value = $r_value, R-squared value = $rsq, p = $p_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db963ce6-0fb1-40c8-a5a5-f422f942166d",
   "metadata": {},
   "source": [
    "### **More plots!**\n",
    "I printed all of them so I could see which ones to possibly use in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "843601e0-ff77-47e9-843f-4d97c204205d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Random` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Random` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/music/Algorithms-of-the-Mind/finalproj/musical_expectation_v1.ipynb:1"
     ]
    }
   ],
   "source": [
    "Random.seed!(704)\n",
    "\n",
    "num_melodies = size(df6, 2)\n",
    "model_means = []\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df6[!, col_idx][1:7]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:6], df6_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df6_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    init_note = melody_sequence[1]\n",
    "    visualize_samples(pf_traces, melody_sequence)\n",
    "end\n",
    "\n",
    "num_melodies = size(df7, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df7[!, col_idx][1:8]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:7], df7_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df7_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    init_note = melody_sequence[1]\n",
    "    visualize_samples(pf_traces, melody_sequence)\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df8, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df8[!, col_idx][1:9]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:8], df8_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df8_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "    \n",
    "    init_note = melody_sequence[1]\n",
    "    visualize_samples(pf_traces, melody_sequence)\n",
    "end\n",
    "\n",
    "\n",
    "num_melodies = size(df9, 2)\n",
    "for col_idx in 1:num_melodies\n",
    "    melody_sequence = df9[!, col_idx][1:10]\n",
    "\n",
    "    obs_notes = make_observations(melody_sequence[1:9], df9_keys[col_idx])\n",
    "    pf_traces = particle_filter(2000, 200, df9_keys[col_idx], obs_notes, melody_sequence[1])\n",
    "\n",
    "    last_notes = Float64[]\n",
    "    for trace in pf_traces\n",
    "        last_note = trace[:sequence][end]\n",
    "        push!(last_notes, last_note)\n",
    "    end\n",
    "\n",
    "    init_note = melody_sequence[1]\n",
    "    visualize_samples(pf_traces, melody_sequence)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f23b0-63f4-47ec-9833-7d03a469221f",
   "metadata": {},
   "source": [
    "### **References**\n",
    "Larson, S. (2004). Musical Forces and Melodic Expectations: Comparing Computer Models and Experimental Results. Music Perception, 21(4), 457–498. https://doi.org/10.1525/mp.2004.21.4.457\n",
    "\n",
    "Morgan, E., Fogel, A., Nair, A., & Patel, A. D. (2019). Statistical learning and Gestalt-like principles predict melodic expectations. Cognition, 189, 23–34. https://doi.org/10.1016/j.cognition.2018.12.015\n",
    "\n",
    "Temperley, D. (2008). A Probabilistic Model of Melody Perception. Cognitive Science, 32(2), 418–444. https://doi.org/10.1080/03640210701864089\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
